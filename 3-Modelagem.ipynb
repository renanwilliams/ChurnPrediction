{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ethical-retention",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils import training_algorithms\n",
    "pd.pandas.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "superb-mason",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.read_csv('BankChurners_modelagem.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "suited-liberia",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pred_df['Attrition_Flag']\n",
    "X = pred_df.drop('Attrition_Flag',axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worst-sheep",
   "metadata": {},
   "source": [
    "- Dividing the dataset between train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "governmental-patch",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominant-press",
   "metadata": {},
   "source": [
    "- Defining the models to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "conditional-veteran",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf1 = DecisionTreeClassifier()\n",
    "clf2 = RandomForestClassifier()\n",
    "clf3 = AdaBoostClassifier()\n",
    "algoritmos = [clf1,clf2,clf3]\n",
    "performances = training_algorithms(X_train,y_train,algoritmos)\n",
    "\n",
    "clf1_trained, cross_val_1 = performances[0][0], performances[0][1]\n",
    "clf2_trained, cross_val_2 = performances[1][0], performances[1][1]\n",
    "clf3_trained, cross_val_3 = performances[2][0], performances[2][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valued-honduras",
   "metadata": {},
   "source": [
    "- Performances on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "colored-vessel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.95134228, 0.95142379, 0.94728033, 0.94763514, 0.94798658,\n",
       "        0.95549958, 0.95341098, 0.95084746, 0.95652174, 0.95725063]),\n",
       " array([0.96345515, 0.96277916, 0.9626556 , 0.96399345, 0.96381579,\n",
       "        0.96880131, 0.96715928, 0.97593361, 0.9611249 , 0.97359736]),\n",
       " array([0.95805369, 0.96345515, 0.96327212, 0.96052632, 0.96080067,\n",
       "        0.96511628, 0.96099585, 0.95986622, 0.94920899, 0.96758105]))"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_1, cross_val_2, cross_val_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "saving-nursing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9519198501824879, 0.9663315607754048, 0.9608876334305073)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_1), np.mean(cross_val_2), np.mean(cross_val_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "simplified-jonathan",
   "metadata": {},
   "source": [
    "# Is there a difference, statistically significant, between the performances of the trained models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cutting-brazil",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shapiro-Wilk and Kolmogorov-Sminorv Test\n",
    "from scipy.stats import shapiro, kstest, f_oneway, ttest_rel, friedmanchisquare, wilcoxon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "temporal-looking",
   "metadata": {},
   "outputs": [],
   "source": [
    "performances_train = [cross_val_1,cross_val_2,cross_val_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ceramic-privilege",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normality Tests for the performance of: Decision Tree, Random Forest and AdaBoost: \n",
      "\n",
      "--------------------\n",
      "Shapiro P-Value: 0.34260931611061096 KS P-Value: 4.549743125515367e-08\n",
      "--------------------\n",
      "Shapiro P-Value: 0.0613606721162796 KS P-Value: 3.687903518225239e-08\n",
      "--------------------\n",
      "Shapiro P-Value: 0.15195178985595703 KS P-Value: 4.4187840587005076e-08\n"
     ]
    }
   ],
   "source": [
    "print('Normality Tests for the performance of: Decision Tree, Random Forest and AdaBoost: \\n')\n",
    "for i in performances_train:\n",
    "    a = shapiro(i)[1]\n",
    "    b = kstest(i,'norm')[1]\n",
    "    print('--------------------')\n",
    "    print(\"Shapiro P-Value:\", a, \"KS P-Value:\", b)      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "infectious-bunch",
   "metadata": {},
   "source": [
    "##### Knowing that the null hypothesis of the Shapiro-Wilk test says that if the p-value of the test is greater than a specific significance level (0.05 in our case), the distribution of the sample is not significantly different from a normal distribution.\n",
    "\n",
    "##### Unlike Shapiro-Wilk hypothesis, the null hypothesis of the Kolmogorov-Sminorv test says that if the p-value of the test is greater than a specific significance level (0.05 in our case), than there is a significant difference between the two distributions compared (the classifier performance distribution and the normal distribution). \n",
    "\n",
    "##### So, based on the p-values calculated before, we can conclude that we do have enough evidences to use parametric methods (assuming that the distribution of the performance of the classifiers are normally distributed) to compare the performance between them.\n",
    "\n",
    "##### First we are going to perform a test, ANOVA, that can check if there is a significant difference between the performance of the group of classifiers. Once we indentifies this difference is statistically significant, we are going to check which of the classifiers performances differ from each other using the T-Test for paired samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "buried-ghana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F_onewayResult(statistic=25.201749217987302, pvalue=6.685637878969156e-07)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_oneway(cross_val_1,cross_val_2,cross_val_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "powered-jason",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalent to the ANOVA oneway but Non-Parametric Test (use this instead of f_oneway method,\n",
    "# incase the data were not normally distributed)\n",
    "\n",
    "# friedmanchisquare(cross_val_clf1,cross_val_clf2,cross_val_clf3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excess-technical",
   "metadata": {},
   "source": [
    "#### Accordingly with ANOVA test, the performance of the classifiers does not have the same distribution, so we are going to perform the T-Test for paired samples to check wich of them have the performance different from the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "stuffed-opportunity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=-8.882499149397468, pvalue=9.505879843437891e-06)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_rel(cross_val_1,cross_val_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "fatty-speaking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=-4.463793685954248, pvalue=0.0015686446983005984)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_rel(cross_val_1,cross_val_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "alleged-arrangement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_relResult(statistic=3.315290114832669, pvalue=0.009007652063853903)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_rel(cross_val_2,cross_val_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "familiar-stone",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Equivalent to the T-Test but Non-Parametric Test (use this instead of ttest_rel method,\n",
    "# incase the data were not normally distributed)\n",
    "\n",
    "# wilcoxon(cross_val_clf1,cross_val_clf2)\n",
    "# wilcoxon(cross_val_clf1,cross_val_clf3)\n",
    "# wilcoxon(cross_val_clf2,cross_val_clf3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "elementary-group",
   "metadata": {},
   "source": [
    "##### As we can see, accordingly with the T-Test, the performance of the algorithms are statistically differente... So, as we saw before that the mean of the Random Forest classifier is greater than the others, we are going to use Random Forest to predict future samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "supreme-benjamin",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_pred = clf2_trained.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "authentic-identification",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 338,  158],\n",
       "        [  43, 2500]], dtype=int64),\n",
       " 0.9613535858488752,\n",
       " 0.9405568096313017,\n",
       " 0.9830908375933937,\n",
       " 0.9338598223099703)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score, accuracy_score\n",
    "confusion_matrix(y_test,RF_pred), f1_score(y_test,RF_pred),precision_score(y_test,RF_pred), recall_score(y_test,RF_pred), accuracy_score(y_test,RF_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "radio-fifth",
   "metadata": {},
   "source": [
    "# The most important features accordingly with Random Fores are: Total_Trans_Amt, Total_Ct_Chng_Q4_Q1 and Total_Revolving_Bal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "visible-hometown",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Income_Category</th>\n",
       "      <th>Total_Relationship_Count</th>\n",
       "      <th>Months_Inactive_12_mon</th>\n",
       "      <th>Contacts_Count_12_mon</th>\n",
       "      <th>Credit_Limit</th>\n",
       "      <th>Total_Revolving_Bal</th>\n",
       "      <th>Total_Amt_Chng_Q4_Q1</th>\n",
       "      <th>Total_Trans_Amt</th>\n",
       "      <th>Total_Ct_Chng_Q4_Q1</th>\n",
       "      <th>Avg_Utilization_Ratio</th>\n",
       "      <th>Marital_Status_Divorced</th>\n",
       "      <th>Marital_Status_Married</th>\n",
       "      <th>Marital_Status_Single</th>\n",
       "      <th>Marital_Status_Unknown</th>\n",
       "      <th>Card_Category_Blue</th>\n",
       "      <th>Card_Category_Gold</th>\n",
       "      <th>Card_Category_Platinum</th>\n",
       "      <th>Card_Category_Silver</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.014731</td>\n",
       "      <td>0.024354</td>\n",
       "      <td>0.021402</td>\n",
       "      <td>0.067857</td>\n",
       "      <td>0.036989</td>\n",
       "      <td>0.043067</td>\n",
       "      <td>0.061157</td>\n",
       "      <td>0.123519</td>\n",
       "      <td>0.090999</td>\n",
       "      <td>0.247042</td>\n",
       "      <td>0.155533</td>\n",
       "      <td>0.083175</td>\n",
       "      <td>0.003989</td>\n",
       "      <td>0.008358</td>\n",
       "      <td>0.008336</td>\n",
       "      <td>0.003167</td>\n",
       "      <td>0.002769</td>\n",
       "      <td>0.001048</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.002046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Gender  Education_Level  Income_Category  Total_Relationship_Count  \\\n",
       "0  0.014731         0.024354         0.021402                  0.067857   \n",
       "\n",
       "   Months_Inactive_12_mon  Contacts_Count_12_mon  Credit_Limit  \\\n",
       "0                0.036989               0.043067      0.061157   \n",
       "\n",
       "   Total_Revolving_Bal  Total_Amt_Chng_Q4_Q1  Total_Trans_Amt  \\\n",
       "0             0.123519              0.090999         0.247042   \n",
       "\n",
       "   Total_Ct_Chng_Q4_Q1  Avg_Utilization_Ratio  Marital_Status_Divorced  \\\n",
       "0             0.155533               0.083175                 0.003989   \n",
       "\n",
       "   Marital_Status_Married  Marital_Status_Single  Marital_Status_Unknown  \\\n",
       "0                0.008358               0.008336                0.003167   \n",
       "\n",
       "   Card_Category_Blue  Card_Category_Gold  Card_Category_Platinum  \\\n",
       "0            0.002769            0.001048                0.000464   \n",
       "\n",
       "   Card_Category_Silver  \n",
       "0              0.002046  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([clf2.feature_importances_],columns=X_train.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
